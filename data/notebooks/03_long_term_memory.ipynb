{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Term Memory Experiments\n",
    "\n",
    "This notebook explores long-term memory functionality, pattern learning, and knowledge management for AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent / \"backend\"))\n",
    "\n",
    "from src.job_automation.core.memory import LongTermMemory, MemoryManager\n",
    "\n",
    "print(\"Long-term memory environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Base Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long-term memory instance\n",
    "ltm = LongTermMemory()\n",
    "\n",
    "# Add job search knowledge\n",
    "ltm.add_knowledge(\n",
    "    \"job_search_strategies\",\n",
    "    \"effective_application_practices\",\n",
    "    {\n",
    "        \"personalize_applications\": True,\n",
    "        \"research_company_culture\": True,\n",
    "        \"tailor_resume_to_job\": True,\n",
    "        \"follow_up_timeline\": \"1-2 weeks\",\n",
    "        \"success_rate_improvement\": \"40-60%\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add company-specific knowledge\n",
    "companies_data = {\n",
    "    \"google\": {\n",
    "        \"culture\": \"innovation-focused\",\n",
    "        \"interview_style\": \"technical + behavioral\",\n",
    "        \"hiring_timeline\": \"4-8 weeks\",\n",
    "        \"remote_policy\": \"hybrid\"\n",
    "    },\n",
    "    \"netflix\": {\n",
    "        \"culture\": \"high-performance\",\n",
    "        \"interview_style\": \"culture-fit heavy\",\n",
    "        \"hiring_timeline\": \"3-6 weeks\",\n",
    "        \"remote_policy\": \"flexible\"\n",
    "    },\n",
    "    \"startups\": {\n",
    "        \"culture\": \"fast-paced\",\n",
    "        \"interview_style\": \"practical + speed\",\n",
    "        \"hiring_timeline\": \"1-3 weeks\",\n",
    "        \"remote_policy\": \"varies\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for company, data in companies_data.items():\n",
    "    ltm.add_knowledge(\n",
    "        \"companies\",\n",
    "        company,\n",
    "        data,\n",
    "        metadata={\"category\": \"tech_companies\", \"verified\": True}\n",
    "    )\n",
    "\n",
    "print(f\"Added knowledge for {len(companies_data)} companies\")\n",
    "print(f\"Knowledge categories: {list(ltm.knowledge_base.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display knowledge\n",
    "job_strategies = ltm.get_knowledge(\"job_search_strategies\", \"effective_application_practices\")\n",
    "print(\"Job Search Strategies:\")\n",
    "print(json.dumps(job_strategies, indent=2))\n",
    "\n",
    "print(\"\\nCompany Information:\")\n",
    "google_info = ltm.get_knowledge(\"companies\", \"google\")\n",
    "print(f\"Google: {json.dumps(google_info, indent=2)}\")\n",
    "\n",
    "# Get all companies\n",
    "all_companies = ltm.get_knowledge(\"companies\")\n",
    "print(f\"\\nTotal companies in knowledge base: {len(all_companies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Tracking and Pattern Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add successful job application experiences\n",
    "successful_experiences = [\n",
    "    {\n",
    "        \"personalized_cover_letter\": True,\n",
    "        \"researched_company\": True,\n",
    "        \"applied_within_24h\": True,\n",
    "        \"followed_up\": True,\n",
    "        \"salary_range_match\": True\n",
    "    },\n",
    "    {\n",
    "        \"personalized_cover_letter\": True,\n",
    "        \"researched_company\": True,\n",
    "        \"applied_within_24h\": False,\n",
    "        \"followed_up\": True,\n",
    "        \"salary_range_match\": True\n",
    "    },\n",
    "    {\n",
    "        \"personalized_cover_letter\": True,\n",
    "        \"researched_company\": False,\n",
    "        \"applied_within_24h\": True,\n",
    "        \"followed_up\": True,\n",
    "        \"salary_range_match\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "for exp_data in successful_experiences:\n",
    "    ltm.add_experience(\"job_application\", exp_data, \"success\")\n",
    "\n",
    "# Add some failed experiences\n",
    "failed_experiences = [\n",
    "    {\n",
    "        \"personalized_cover_letter\": False,\n",
    "        \"researched_company\": False,\n",
    "        \"applied_within_24h\": False,\n",
    "        \"followed_up\": False,\n",
    "        \"salary_range_match\": False\n",
    "    },\n",
    "    {\n",
    "        \"personalized_cover_letter\": False,\n",
    "        \"researched_company\": True,\n",
    "        \"applied_within_24h\": False,\n",
    "        \"followed_up\": False,\n",
    "        \"salary_range_match\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "for exp_data in failed_experiences:\n",
    "    ltm.add_experience(\"job_application\", exp_data, \"failure\")\n",
    "\n",
    "print(f\"Added {len(successful_experiences)} successful and {len(failed_experiences)} failed experiences\")\n",
    "print(f\"Total experiences: {len(ltm.experiences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze learned patterns\n",
    "patterns = ltm.get_patterns(\"job_application\")\n",
    "print(\"Learned Patterns:\")\n",
    "print(json.dumps(patterns, indent=2))\n",
    "\n",
    "# Visualize pattern frequencies\n",
    "if patterns and \"success_patterns\" in patterns:\n",
    "    success_frequencies = [p[\"frequency\"] for p in patterns[\"success_patterns\"]]\n",
    "    failure_frequencies = [p[\"frequency\"] for p in patterns.get(\"failure_patterns\", [])]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    if success_frequencies:\n",
    "        plt.hist(success_frequencies, bins=5, alpha=0.7, color='green')\n",
    "        plt.title('Success Pattern Frequencies')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if failure_frequencies:\n",
    "        plt.hist(failure_frequencies, bins=5, alpha=0.7, color='red')\n",
    "        plt.title('Failure Pattern Frequencies')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Analysis and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert experiences to DataFrame for analysis\n",
    "experiences_df = pd.DataFrame(ltm.experiences)\n",
    "\n",
    "if not experiences_df.empty:\n",
    "    print(\"Experience Analysis:\")\n",
    "    print(f\"Total experiences: {len(experiences_df)}\")\n",
    "    print(f\"Success rate: {(experiences_df['outcome'] == 'success').mean():.2%}\")\n",
    "    \n",
    "    # Analyze outcomes by type\n",
    "    outcome_counts = experiences_df['outcome'].value_counts()\n",
    "    print(f\"\\nOutcome distribution:\")\n",
    "    for outcome, count in outcome_counts.items():\n",
    "        print(f\"  {outcome}: {count}\")\n",
    "    \n",
    "    # Plot outcome distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    outcome_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title('Experience Outcomes Distribution')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze experience data features\n",
    "    # Extract features from the data column\n",
    "    features_data = []\n",
    "    for _, row in experiences_df.iterrows():\n",
    "        feature_row = row['data'].copy()\n",
    "        feature_row['outcome'] = row['outcome']\n",
    "        features_data.append(feature_row)\n",
    "    \n",
    "    features_df = pd.DataFrame(features_data)\n",
    "    \n",
    "    # Calculate success rates by feature\n",
    "    print(\"\\nSuccess rates by feature:\")\n",
    "    for column in features_df.columns:\n",
    "        if column != 'outcome' and features_df[column].dtype == bool:\n",
    "            success_rate = features_df[features_df[column] == True]['outcome'].apply(lambda x: x == 'success').mean()\n",
    "            print(f\"  {column}: {success_rate:.2%}\")\n",
    "else:\n",
    "    print(\"No experiences to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not experiences_df.empty and 'features_df' in locals():\n",
    "    # Convert boolean features to numeric for correlation analysis\n",
    "    numeric_features = features_df.copy()\n",
    "    for col in numeric_features.columns:\n",
    "        if numeric_features[col].dtype == bool:\n",
    "            numeric_features[col] = numeric_features[col].astype(int)\n",
    "    \n",
    "    # Convert outcome to numeric (1 for success, 0 for failure)\n",
    "    numeric_features['outcome_numeric'] = (numeric_features['outcome'] == 'success').astype(int)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = numeric_features.drop('outcome', axis=1).corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show correlations with success outcome\n",
    "    outcome_correlations = correlation_matrix['outcome_numeric'].drop('outcome_numeric').sort_values(ascending=False)\n",
    "    print(\"Correlations with success outcome:\")\n",
    "    for feature, corr in outcome_correlations.items():\n",
    "        print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Manager Integration Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full memory manager with both short and long-term memory\n",
    "manager = MemoryManager()\n",
    "\n",
    "# Add knowledge through manager\n",
    "manager.add_knowledge(\n",
    "    \"interview_preparation\",\n",
    "    \"technical_interview_tips\",\n",
    "    {\n",
    "        \"practice_coding_problems\": True,\n",
    "        \"understand_system_design\": True,\n",
    "        \"prepare_behavioral_examples\": True,\n",
    "        \"research_interviewer_background\": True,\n",
    "        \"preparation_time_recommended\": \"2-4 weeks\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add experiences through manager\n",
    "interview_experiences = [\n",
    "    {\n",
    "        \"prepared_coding_problems\": True,\n",
    "        \"researched_company\": True,\n",
    "        \"mock_interviews\": 3,\n",
    "        \"prepared_questions\": True\n",
    "    },\n",
    "    {\n",
    "        \"prepared_coding_problems\": False,\n",
    "        \"researched_company\": True,\n",
    "        \"mock_interviews\": 0,\n",
    "        \"prepared_questions\": False\n",
    "    }\n",
    "]\n",
    "\n",
    "manager.add_experience(\"interview\", interview_experiences[0], \"success\")\n",
    "manager.add_experience(\"interview\", interview_experiences[1], \"failure\")\n",
    "\n",
    "# Get comprehensive memory stats\n",
    "stats = manager.get_memory_stats()\n",
    "print(\"Comprehensive Memory Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Test knowledge retrieval\n",
    "interview_tips = manager.get_knowledge(\"interview_preparation\", \"technical_interview_tips\")\n",
    "print(\"\\nInterview Tips from Knowledge Base:\")\n",
    "print(json.dumps(interview_tips, indent=2))\n",
    "\n",
    "# Test experience retrieval\n",
    "interview_experiences = manager.get_experiences(\"interview\")\n",
    "print(f\"\\nInterview Experiences: {len(interview_experiences)} recorded\")\n",
    "\n",
    "# Test pattern learning\n",
    "interview_patterns = manager.get_patterns(\"interview\")\n",
    "print(\"\\nLearned Interview Patterns:\")\n",
    "if interview_patterns:\n",
    "    print(json.dumps(interview_patterns, indent=2))\n",
    "else:\n",
    "    print(\"No patterns learned yet (need more data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile experiment results\n",
    "experiment_results = {\n",
    "    \"experiment_date\": datetime.now().isoformat(),\n",
    "    \"knowledge_base_size\": len(ltm.knowledge_base),\n",
    "    \"total_experiences\": len(ltm.experiences),\n",
    "    \"patterns_learned\": len(ltm.patterns),\n",
    "    \"success_rate\": (experiences_df['outcome'] == 'success').mean() if not experiences_df.empty else 0,\n",
    "    \"memory_manager_stats\": stats\n",
    "}\n",
    "\n",
    "# Add pattern analysis if available\n",
    "if 'outcome_correlations' in locals():\n",
    "    experiment_results[\"feature_correlations\"] = outcome_correlations.to_dict()\n",
    "\n",
    "# Save results\n",
    "output_dir = Path.cwd().parent / \"experiments\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(output_dir / \"long_term_memory_experiment.json\", \"w\") as f:\n",
    "    json.dump(experiment_results, f, indent=2)\n",
    "\n",
    "print(f\"Experiment results saved to {output_dir / 'long_term_memory_experiment.json'}\")\n",
    "\n",
    "# Also save the knowledge base for future use\n",
    "knowledge_export = {\n",
    "    \"knowledge_base\": ltm.knowledge_base,\n",
    "    \"export_date\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(output_dir / \"knowledge_base_export.json\", \"w\") as f:\n",
    "    json.dump(knowledge_export, f, indent=2)\n",
    "\n",
    "print(f\"Knowledge base exported to {output_dir / 'knowledge_base_export.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}