# Real Job Scraping Implementation

## Overview

This document explains how the real web scraping system works and how it uses LLMs to navigate and extract job information from company career pages.

## How It Works

### 1. **Multi-Tiered Discovery System**

```
1. Real Web Scraping (Primary)
   ‚Üì (if fails)
2. AI-Generated Jobs (Secondary) 
   ‚Üì (if fails)
3. Demo/Fallback Jobs (Tertiary)
```

### 2. **Real Web Scraping Process**

#### **Phase 1: Career Page Discovery**
```typescript
// Multiple strategies to find career pages
const careerPatterns = [
  '/careers', '/jobs', '/opportunities', 
  '/join-us', '/work-with-us', '/hiring'
];

// 1. Try common URL patterns
// 2. Use LLM to predict career page URL
// 3. Validate page exists and contains job content
```

#### **Phase 2: LLM-Powered Page Analysis**
```typescript
// Send HTML to OpenAI GPT-4 for analysis
const prompt = `
Analyze this career page HTML and extract job listings.
Find all software engineering/technical roles.
Return structured JSON with:
- title, url, location, department, type, description
`;
```

#### **Phase 3: Individual Job Page Processing**
```typescript
// For each job found, fetch detailed page
// Extract comprehensive job information:
// - Full description
// - Requirements list  
// - Salary range
// - Application process
```

## LLM Navigation Strategy

### **HTML Analysis with GPT-4**
The system uses OpenAI's GPT-4 to:

1. **Parse Career Page Structure**
   - Identify job listing containers
   - Extract job titles and links
   - Detect pagination or filters

2. **Extract Job Details**
   - Parse complex HTML layouts
   - Identify key information sections
   - Handle different career page formats

3. **Navigate Application Flow**
   - Find "Apply Now" buttons
   - Extract application URLs
   - Understand multi-step processes

### **Example LLM Analysis**

**Input HTML:**
```html
<div class="job-listing">
  <h3><a href="/careers/senior-engineer">Senior Software Engineer</a></h3>
  <p>Location: Berlin, Germany</p>
  <p>Department: Engineering</p>
</div>
```

**LLM Output:**
```json
[{
  "title": "Senior Software Engineer",
  "url": "https://company.com/careers/senior-engineer",
  "location": "Berlin, Germany", 
  "department": "Engineering",
  "type": "Full-time"
}]
```

## Technical Implementation

### **Backend Proxy Server**

**File:** `vite-proxy.js`
- Handles HTTP requests to avoid CORS
- Implements robots.txt compliance
- Provides HTML sanitization
- Manages rate limiting

```bash
# Start the proxy server
npm run proxy

# Run full development environment
npm run dev:full
```

### **Real Job Scraper Service**

**File:** `src/services/realJobScraper.ts`
- Main scraping orchestration
- LLM integration for HTML analysis
- Job detail extraction
- Error handling and fallbacks

### **Enhanced Autonomous Agent**

**File:** `src/services/autonomousJobAgent.ts`
- Integrates real scraping as primary method
- Falls back to AI generation if scraping fails
- Provides clear job source indicators

## Job Source Indicators

The system now clearly shows job sources in the UI:

- üîç **Real** - Scraped from actual career pages
- ü§ñ **AI** - Generated by OpenAI based on company profile  
- üìã **Demo** - Fallback demo jobs when APIs unavailable

## Trade Republic Example

For Trade Republic specifically:

### **Before (AI Generated)**
```
‚ùå Created fake jobs using company info
‚ùå No real career page verification
‚ùå Constructed application URLs
```

### **After (Real Scraping)**
```
‚úÖ Attempts to scrape https://traderepublic.com/careers
‚úÖ Extracts actual job postings
‚úÖ Validates application links
‚úÖ Falls back gracefully if scraping fails
```

## Development Workflow

### **1. Start Full Development Environment**
```bash
# Terminal 1: Start proxy server
npm run proxy

# Terminal 2: Start frontend
npm run dev

# Or combined:
npm run dev:full
```

### **2. Test Real Scraping**
1. Click "Apply Here" on any company
2. Watch the agent steps for scraping progress
3. Check job source badges (üîç Real vs ü§ñ AI)

### **3. Debug Scraping Issues**
- Check proxy server logs at http://localhost:3001
- Monitor network requests in browser dev tools
- Review agent steps for error messages

## Architecture Benefits

### **Reliability**
- Multiple fallback layers
- Graceful degradation
- Clear error handling

### **Transparency** 
- Shows job source (real vs generated)
- Displays scraping steps to user
- Provides debugging information

### **Scalability**
- Proxy server can be deployed independently
- LLM analysis handles diverse page formats
- Modular scraping components

## Next Steps

### **Enhancements**
1. **Batch Scraping** - Process multiple companies simultaneously
2. **Caching** - Store scraped jobs to reduce API calls
3. **Scheduling** - Regular background job discovery
4. **Analytics** - Track scraping success rates

### **Production Deployment**
1. **Dedicated Backend** - Replace proxy with proper API service
2. **Rate Limiting** - Implement proper request throttling  
3. **Monitoring** - Add logging and error tracking
4. **Compliance** - Ensure robots.txt and ToS compliance

## Testing

### **Manual Testing**
```bash
# Test with Trade Republic
1. Start development environment
2. Navigate to Company Directory
3. Click "Apply Here" on Trade Republic
4. Verify real scraping attempt in agent steps
5. Check job source indicators
```

### **API Testing**
```bash
# Test proxy server directly
curl -X POST http://localhost:3001/api/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://traderepublic.com/careers"}'
```

This implementation provides a robust foundation for real job discovery while maintaining the existing AI-powered fallbacks for reliability and user experience.